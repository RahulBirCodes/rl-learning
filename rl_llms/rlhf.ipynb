{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RLHF Demo\n",
    "Run post training on a pretrained GPT-2 model to understand RLHF. Steps will be SFT -> train reward model -> run grpo on pretrained llm on reward model. Rather than using TRL, I will be implementing grpo myself. Implementation will start with single gpu and then scaled to distributed system."
   ],
   "id": "6a402223a4106937"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T00:36:27.162345Z",
     "start_time": "2025-08-21T00:36:03.947157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.eval()\n",
    "\n",
    "prompt = \"The usual weather in California is\"\n",
    "inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=1000,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ],
   "id": "a36fde68ad87b98c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The usual weather in California is a bit of a mess.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Supervised fine tuning\n",
    "\n",
    "What I need to do:\n",
    "1. Preprocess data into chat template with EOS token. Ensure data is padded and make sure batches are truncated to fit context length.\n",
    "2. Iterate through every batch and for each one calculate the loss (ONLY on the last assistant completion so the model learns prompt prediction). We use cross entropy btw.\n",
    "3. Run a number of epochs on it.\n",
    "4. Keep single threaded till we implement grpo as well."
   ],
   "id": "fb9e9f51ec732eb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T02:16:26.106855Z",
     "start_time": "2025-08-21T02:16:18.786482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset, load_dataset_builder, get_dataset_split_names\n",
    "from torch.utils.data import DataLoader\n",
    "from pprint import pprint\n",
    "\n",
    "# ---------------\n",
    "# hyperparameters\n",
    "num_epochs = 5\n",
    "batch_size = 1\n",
    "# ---------------\n",
    "\n",
    "# create dataset train/val/test splits\n",
    "train_sft_dataset = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split='train_sft').select(range(1000))\n",
    "train_split_size = int(0.9 * len(train_sft_dataset))\n",
    "train_split = train_sft_dataset.select(range(train_split_size))\n",
    "val_split = train_sft_dataset.select(range(train_split_size, len(train_sft_dataset)))\n",
    "\n",
    "# create chat template for tokenizer to use, gpt2 uses eos token so we need to add that as well\n",
    "tokenizer.chat_template = \"\"\"\n",
    "{%- for message in messages %}\n",
    "    {{- '<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n' }}\n",
    "{%- endfor %}\n",
    "{%- if add_generation_prompt %}\n",
    "    {{- '<|im_start|>assistant\\n' }}\n",
    "{%- else %}\n",
    "    {{- eos_token }}\n",
    "{%- endif %}\n",
    "\"\"\"\n",
    "\n",
    "# preprocess data and create dataloader\n",
    "ending_msg_token_len = len(tokenizer.encode('<|im_end|>\\n'))\n",
    "def add_chat_tem(example):\n",
    "    # convert to chat template and keep track of # of tokens in last generation\n",
    "    example['input_ids'] = tokenizer.apply_chat_template(example['messages'], tokenize=True, add_special_tokens=False)\n",
    "    example['last_gen_token_len'] = len(tokenizer.encode(example['messages'][-1]['content'], add_special_tokens=False)) + ending_msg_token_len\n",
    "    return example\n",
    "\n",
    "train_split = train_split.map(add_chat_tem)\n",
    "val_split = val_split.map(add_chat_tem)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_split,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=lambda b: b\n",
    ")"
   ],
   "id": "b8e444928958616b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 900/900 [00:04<00:00, 190.61 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 161.10 examples/s]\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T02:16:27.657239Z",
     "start_time": "2025-08-21T02:16:27.652034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# training run\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        # When given multi-turn data, only include generation of final turn in loss\n",
    "        pprint(batch[0]['messages'])\n",
    "        print(\"\\n\\n\\n\\n\")\n",
    "\n",
    "\n",
    "        print(tokenizer.decode(batch[0]['input_ids'][-(batch[0]['last_gen_token_len']+1):]))\n",
    "        print(\"----------\")\n",
    "        break\n",
    "    break"
   ],
   "id": "71d7c703271a5893",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'How can I achieve a smooth surface on my cookie for decorating?\\n'\n",
      "             'Generate according to: He?s keeping his eye on you! Shaped '\n",
      "             'cookie gets a poured on coating of thinned royal icing that '\n",
      "             'provides a smooth base for your ghoulish facial features.\\n'\n",
      "             'Press cookie dough into mummy head cavity of cookie pan. Bake '\n",
      "             'and cool.\\n'\n",
      "             'Decorate using royal icing. Divide icing and tint black and '\n",
      "             'yellow; reserve some white.\\n'\n",
      "             'Thin a portion of the white icing. Place cookies on cooling grid '\n",
      "             'over waxed paper. Cover with thinned icing, tap grid gently to '\n",
      "             'remove air bubbles. Allow to dry and repeat if necessary.\\n'\n",
      "             'Use tip 3 and yellow icing to pipe ball eye. Use tip 2 and black '\n",
      "             'icing to pipe dot eye center. Use tip 2 and white icing to pipe '\n",
      "             'dot and shaped nose and pull-out dot ears.\\n'\n",
      "             'Use tip 2 and black icing to pipe in mouth and add pull-out dot '\n",
      "             'eyebrows.\\n'\n",
      "             'Use tip 1 and white icing to pipe in teeth.',\n",
      "  'role': 'user'},\n",
      " {'content': 'To achieve a smooth surface on your cookie for decorating, you '\n",
      "             'can pour a thinned royal icing coating over it. First, bake and '\n",
      "             'cool your cookie. Then, divide your royal icing into different '\n",
      "             'colors, including black, yellow, and white. Thin a portion of '\n",
      "             'the white icing, and place your cookie on a cooling grid over '\n",
      "             'waxed paper. Cover the cookie with the thinned icing, tapping '\n",
      "             'the grid gently to remove air bubbles. Allow it to dry and '\n",
      "             'repeat if necessary. Once your base is smooth, decorate your '\n",
      "             'cookie using different tips and colors of icing to create your '\n",
      "             'desired design.',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Can you recommend any other colors to use for decorating the '\n",
      "             'cookie besides black, yellow, and white?',\n",
      "  'role': 'user'},\n",
      " {'content': 'Certainly! You can use any colors you like for decorating your '\n",
      "             'cookie, depending on the desired theme or occasion. Here are '\n",
      "             'some ideas:\\n'\n",
      "             '\\n'\n",
      "             '- Halloween colors: orange, green, and purple\\n'\n",
      "             '- Christmas colors: red, green, and white\\n'\n",
      "             \"- Valentine's Day colors: pink, red, and white\\n\"\n",
      "             '- Easter colors: pastel shades of pink, blue, yellow, and green\\n'\n",
      "             '- Patriotic colors: red, white, and blue\\n'\n",
      "             '\\n'\n",
      "             'Feel free to experiment and have fun with different color '\n",
      "             'combinations!',\n",
      "  'role': 'assistant'}]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Certainly! You can use any colors you like for decorating your cookie, depending on the desired theme or occasion. Here are some ideas:\n",
      "\n",
      "- Halloween colors: orange, green, and purple\n",
      "- Christmas colors: red, green, and white\n",
      "- Valentine's Day colors: pink, red, and white\n",
      "- Easter colors: pastel shades of pink, blue, yellow, and green\n",
      "- Patriotic colors: red, white, and blue\n",
      "\n",
      "Feel free to experiment and have fun with different color combinations!<|im_end|>\n",
      "<|endoftext|>\n",
      "----------\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create the reward model",
   "id": "6e77f8f5907b1bc8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T19:41:25.928628Z",
     "start_time": "2025-08-20T19:41:25.919996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The reward model generates a single logit representing the probability of that response (we use Bradley-Terry model of preferences)\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, input_size * 4)\n",
    "        self.fc2 = nn.Linear(input_size * 4, 1)\n",
    "\n",
    "'''\n",
    "Preference training loop steps:\n",
    "1. Iterate through synthetic data of preferences.\n",
    "2. Use the final hidden state last embedding as input to reward network.\n",
    "3. Do that for both (otherwise you can use synthetic data and feed into the network the prompt + the response)\n",
    "4. Use that to get the embeddings for both (just do one pass)\n",
    "5. Calculate the loss based on Bradley-Terry and do backprop on the reward model network (you can mean the sums so you do it batchwise)\n",
    "\n",
    "The idea we'll use is take the prompt reward string to get rewrd but only train on prompt to avoid mismatch problem.\n",
    "'''\n"
   ],
   "id": "daf721071ca1e02e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPreference training loop steps:\\n1. Iterate through synthetic data of preferences.\\n2. Use the final hidden state last embedding as input to reward network.\\n3. Do that for both (otherwise you can use synthetic data and feed into the network the prompt + the response)\\n4. Use that to get the embeddings for both (just do one pass)\\n5. Calculate the loss based on Bradley-Terry and do backprop on the reward model network (you can mean the sums so you do it batchwise)\\n\\nThe idea we'll use is take the prompt reward string to get rewrd but only train on prompt to avoid mismatch problem.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T19:58:32.609858Z",
     "start_time": "2025-08-20T19:58:31.662841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_data = load_dataset('HuggingFaceH4/no_robots')['train']\n",
    "train_data[0]"
   ],
   "id": "d09fc1eced2f7d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Please summarize the goals for scientists in this text:\\n\\nWithin three days, the intertwined cup nest of grasses was complete, featuring a canopy of overhanging grasses to conceal it. And decades later, it served as Rinkert’s portal to the past inside the California Academy of Sciences. Information gleaned from such nests, woven long ago from species in plant communities called transitional habitat, could help restore the shoreline in the future. Transitional habitat has nearly disappeared from the San Francisco Bay, and scientists need a clearer picture of its original species composition—which was never properly documented. With that insight, conservation research groups like the San Francisco Bay Bird Observatory can help guide best practices when restoring the native habitat that has long served as critical refuge for imperiled birds and animals as adjacent marshes flood more with rising sea levels. “We can’t ask restoration ecologists to plant nonnative species or to just take their best guess and throw things out there,” says Rinkert.',\n",
       " 'prompt_id': '627a77298cf96a309aa35a62207c4164e22a66f6db79119506228f28ddc0f947',\n",
       " 'messages': [{'content': 'Please summarize the goals for scientists in this text:\\n\\nWithin three days, the intertwined cup nest of grasses was complete, featuring a canopy of overhanging grasses to conceal it. And decades later, it served as Rinkert’s portal to the past inside the California Academy of Sciences. Information gleaned from such nests, woven long ago from species in plant communities called transitional habitat, could help restore the shoreline in the future. Transitional habitat has nearly disappeared from the San Francisco Bay, and scientists need a clearer picture of its original species composition—which was never properly documented. With that insight, conservation research groups like the San Francisco Bay Bird Observatory can help guide best practices when restoring the native habitat that has long served as critical refuge for imperiled birds and animals as adjacent marshes flood more with rising sea levels. “We can’t ask restoration ecologists to plant nonnative species or to just take their best guess and throw things out there,” says Rinkert.',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Scientists are studying nests hoping to learn about transitional habitats that could help restore the shoreline of San Francisco Bay.',\n",
       "   'role': 'assistant'}],\n",
       " 'category': 'Summarize'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6190e2927bd84be6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
