{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RLHF Demo\n",
    "Run post training on a pretrained GPT-2 model to understand RLHF. Steps will be SFT -> train reward model -> run grpo on pretrained llm on reward model. Rather than using TRL, I will be implementing grpo myself. Implementation will start with single gpu and then scaled to distributed system."
   ],
   "id": "6a402223a4106937"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T00:36:27.162345Z",
     "start_time": "2025-08-21T00:36:03.947157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.eval()\n",
    "\n",
    "prompt = \"The usual weather in California is\"\n",
    "inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=1000,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ],
   "id": "a36fde68ad87b98c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The usual weather in California is a bit of a mess.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Supervised fine tuning\n",
    "\n",
    "What I need to do:\n",
    "1. Preprocess data into chat template with EOS token. Ensure data is padded and make sure batches are truncated to fit context length.\n",
    "2. Iterate through every batch and for each one calculate the loss (ONLY on the last assistant completion so the model learns prompt prediction). We use cross entropy btw.\n",
    "3. Run a number of epochs on it.\n",
    "4. Keep single threaded till we implement grpo as well."
   ],
   "id": "fb9e9f51ec732eb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T22:16:10.975823Z",
     "start_time": "2025-08-20T22:16:09.932273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset, load_dataset_builder, get_dataset_split_names\n",
    "from torch.utils.data import DataLoader\n",
    "from pprint import pprint\n",
    "\n",
    "# ---------------\n",
    "# hyperparameters\n",
    "num_epochs = 5\n",
    "batch_size = 2\n",
    "# ---------------\n",
    "\n",
    "train_data = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split='train_sft').select(range(1000))\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size, collate_fn=lambda b: b)\n",
    "\n",
    "# create chat template for tokenizer to use, gpt2 uses eos token so we need to add that as well\n",
    "tokenizer.chat_template = \"\"\"\n",
    "{%- for message in messages %}\n",
    "    {{- '<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n' }}\n",
    "{%- endfor %}\n",
    "{%- if add_generation_prompt %}\n",
    "    {{- '<|im_start|>assistant\\n' }}\n",
    "{%- else %}\n",
    "    {{- eos_token }}\n",
    "{%- endif %}\n",
    "\"\"\"\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch in train_dataloader:\n",
    "#         # When given multi-turn data, only include generation of final turn in loss\n",
    "#         # pprint(batch)\n",
    "#         print(\"----------\")\n",
    "#         chats = [gen_chat_template(prompt) for prompt in batch]\n",
    "#         print(chats)\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "tokenizer.apply_chat_template(train_data[0])\n"
   ],
   "id": "b8e444928958616b",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[45]\u001B[39m\u001B[32m, line 30\u001B[39m\n\u001B[32m     15\u001B[39m     chat_temp = \u001B[33m'\u001B[39m\u001B[33m'\u001B[39m.join([\n\u001B[32m     16\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m<|im_start|>\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmessage[\u001B[33m'\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mmessage[\u001B[33m'\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     17\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m message \u001B[38;5;129;01min\u001B[39;00m prompt[\u001B[33m'\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m'\u001B[39m]])\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# for epoch in range(num_epochs):\u001B[39;00m\n\u001B[32m     21\u001B[39m \u001B[38;5;66;03m#     for batch in train_dataloader:\u001B[39;00m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m#         # When given multi-turn data, only include generation of final turn in loss\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     27\u001B[39m \u001B[38;5;66;03m#         break\u001B[39;00m\n\u001B[32m     28\u001B[39m \u001B[38;5;66;03m#     break\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply_chat_template\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1620\u001B[39m, in \u001B[36mPreTrainedTokenizerBase.apply_chat_template\u001B[39m\u001B[34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001B[39m\n\u001B[32m   1617\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m tokenizer_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1618\u001B[39m     tokenizer_kwargs = {}\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m chat_template = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_chat_template\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchat_template\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(conversation, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)) \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[32m   1623\u001B[39m     \u001B[38;5;28misinstance\u001B[39m(conversation[\u001B[32m0\u001B[39m], (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(conversation[\u001B[32m0\u001B[39m], \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1624\u001B[39m ):\n\u001B[32m   1625\u001B[39m     conversations = conversation\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1798\u001B[39m, in \u001B[36mPreTrainedTokenizerBase.get_chat_template\u001B[39m\u001B[34m(self, chat_template, tools)\u001B[39m\n\u001B[32m   1796\u001B[39m         chat_template = \u001B[38;5;28mself\u001B[39m.chat_template\n\u001B[32m   1797\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1798\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1799\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mCannot use chat template functions because tokenizer.chat_template is not set and no template \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1800\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33margument was passed! For information about writing templates and setting the \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1801\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mtokenizer.chat_template attribute, please see the documentation at \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1802\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mhttps://huggingface.co/docs/transformers/main/en/chat_templating\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1803\u001B[39m         )\n\u001B[32m   1805\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m chat_template\n",
      "\u001B[31mValueError\u001B[39m: Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T20:59:06.556866Z",
     "start_time": "2025-08-20T20:59:06.552149Z"
    }
   },
   "cell_type": "code",
   "source": "pprint(train_data[0])",
   "id": "1b65b3285d9a2e40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'content': 'These instructions apply to section-based themes '\n",
      "                          '(Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo '\n",
      "                          '2.0+, Mobilia 5.0+). What theme version am I '\n",
      "                          'using?\\n'\n",
      "                          'On your Collections pages & Featured Collections '\n",
      "                          'sections, you can easily show the secondary image '\n",
      "                          'of a product on hover by enabling one of the '\n",
      "                          \"theme's built-in settings!\\n\"\n",
      "                          'Your Collection pages & Featured Collections '\n",
      "                          'sections will now display the secondary product '\n",
      "                          'image just by hovering over that product image '\n",
      "                          'thumbnail.\\n'\n",
      "                          'Does this feature apply to all sections of the '\n",
      "                          'theme or just specific ones as listed in the text '\n",
      "                          'material?',\n",
      "               'role': 'user'},\n",
      "              {'content': 'This feature only applies to Collection pages and '\n",
      "                          'Featured Collections sections of the section-based '\n",
      "                          'themes listed in the text material.',\n",
      "               'role': 'assistant'},\n",
      "              {'content': 'Can you guide me through the process of enabling '\n",
      "                          'the secondary image hover feature on my Collection '\n",
      "                          'pages and Featured Collections sections?',\n",
      "               'role': 'user'},\n",
      "              {'content': 'Sure, here are the steps to enable the secondary '\n",
      "                          'image hover feature on your Collection pages and '\n",
      "                          'Featured Collections sections:\\n'\n",
      "                          '\\n'\n",
      "                          '1. Log in to your Shopify account and go to your '\n",
      "                          'Online Store.\\n'\n",
      "                          '2. Click on Customize theme for the section-based '\n",
      "                          'theme you are using.\\n'\n",
      "                          '3. Navigate to the Collection pages or Featured '\n",
      "                          'Collections section where you want to enable the '\n",
      "                          'secondary image hover feature.\\n'\n",
      "                          \"4. With the section open, click on the section's \"\n",
      "                          'setting (gear) icon in the top-left corner.\\n'\n",
      "                          '5. In the settings panel that appears, look for an '\n",
      "                          \"option labeled 'Image display' or 'Image hover'.\\n\"\n",
      "                          \"6. If available, select 'Show secondary image on \"\n",
      "                          \"hover'.\\n\"\n",
      "                          '7. Save the changes and preview the '\n",
      "                          'Collection/Featured Collection page to see the '\n",
      "                          'effect.\\n'\n",
      "                          '\\n'\n",
      "                          \"If you're having trouble finding the setting, the \"\n",
      "                          \"best thing to do is refer to your theme's \"\n",
      "                          'documentation, since the location and labeling of '\n",
      "                          'settings can vary between themes.',\n",
      "               'role': 'assistant'},\n",
      "              {'content': 'Can you provide me with a link to the documentation '\n",
      "                          'for my theme?',\n",
      "               'role': 'user'},\n",
      "              {'content': \"I don't have access to your store's theme \"\n",
      "                          'information. However, you can usually find the '\n",
      "                          'documentation for your theme by going to the '\n",
      "                          'shopify theme store, finding your theme and '\n",
      "                          \"clicking on the 'support' link located in the \"\n",
      "                          'bottom right corner of the page. Alternatively, you '\n",
      "                          'can do a google search for the name of your theme '\n",
      "                          \"followed by 'documentation' or 'user guide'.\",\n",
      "               'role': 'assistant'},\n",
      "              {'content': 'Can you confirm if this feature also works for the '\n",
      "                          'Quick Shop section of my theme?',\n",
      "               'role': 'user'},\n",
      "              {'content': 'The secondary image hover feature may or may not '\n",
      "                          'work for your Quick Shop section, depending on the '\n",
      "                          'configuration of your theme. Some themes include '\n",
      "                          'this feature in the Quick Shop section by default, '\n",
      "                          'while others may require additional customization. '\n",
      "                          'To check if this feature is available for the Quick '\n",
      "                          'Shop section of your theme, follow these steps:\\n'\n",
      "                          '\\n'\n",
      "                          '1. Go to the Quick Shop section where you would '\n",
      "                          'like to enable the feature. 2. Click on the Quick '\n",
      "                          \"Shop settings icon (gear icon) and look for 'Image \"\n",
      "                          \"display' or 'Image hover'. 3. If available, select \"\n",
      "                          \"'Show secondary image on hover'. 4. Save the \"\n",
      "                          'changes. If this option is not available in your '\n",
      "                          'Quick Shop section settings, you may need to reach '\n",
      "                          'out to your theme developer for assistance with '\n",
      "                          'customizing your Quick Shop section to include this '\n",
      "                          'feature.',\n",
      "               'role': 'assistant'}],\n",
      " 'prompt': 'These instructions apply to section-based themes (Responsive 6.0+, '\n",
      "           'Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme '\n",
      "           'version am I using?\\n'\n",
      "           'On your Collections pages & Featured Collections sections, you can '\n",
      "           'easily show the secondary image of a product on hover by enabling '\n",
      "           \"one of the theme's built-in settings!\\n\"\n",
      "           'Your Collection pages & Featured Collections sections will now '\n",
      "           'display the secondary product image just by hovering over that '\n",
      "           'product image thumbnail.\\n'\n",
      "           'Does this feature apply to all sections of the theme or just '\n",
      "           'specific ones as listed in the text material?',\n",
      " 'prompt_id': 'f0e37e9f7800261167ce91143f98f511f768847236f133f2d0aed60b444ebe57'}\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create the reward model",
   "id": "6e77f8f5907b1bc8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T19:41:25.928628Z",
     "start_time": "2025-08-20T19:41:25.919996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The reward model generates a single logit representing the probability of that response (we use Bradley-Terry model of preferences)\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, input_size * 4)\n",
    "        self.fc2 = nn.Linear(input_size * 4, 1)\n",
    "\n",
    "'''\n",
    "Preference training loop steps:\n",
    "1. Iterate through synthetic data of preferences.\n",
    "2. Use the final hidden state last embedding as input to reward network.\n",
    "3. Do that for both (otherwise you can use synthetic data and feed into the network the prompt + the response)\n",
    "4. Use that to get the embeddings for both (just do one pass)\n",
    "5. Calculate the loss based on Bradley-Terry and do backprop on the reward model network (you can mean the sums so you do it batchwise)\n",
    "\n",
    "The idea we'll use is take the prompt reward string to get rewrd but only train on prompt to avoid mismatch problem.\n",
    "'''\n"
   ],
   "id": "daf721071ca1e02e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPreference training loop steps:\\n1. Iterate through synthetic data of preferences.\\n2. Use the final hidden state last embedding as input to reward network.\\n3. Do that for both (otherwise you can use synthetic data and feed into the network the prompt + the response)\\n4. Use that to get the embeddings for both (just do one pass)\\n5. Calculate the loss based on Bradley-Terry and do backprop on the reward model network (you can mean the sums so you do it batchwise)\\n\\nThe idea we'll use is take the prompt reward string to get rewrd but only train on prompt to avoid mismatch problem.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T19:58:32.609858Z",
     "start_time": "2025-08-20T19:58:31.662841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_data = load_dataset('HuggingFaceH4/no_robots')['train']\n",
    "train_data[0]"
   ],
   "id": "d09fc1eced2f7d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Please summarize the goals for scientists in this text:\\n\\nWithin three days, the intertwined cup nest of grasses was complete, featuring a canopy of overhanging grasses to conceal it. And decades later, it served as Rinkert’s portal to the past inside the California Academy of Sciences. Information gleaned from such nests, woven long ago from species in plant communities called transitional habitat, could help restore the shoreline in the future. Transitional habitat has nearly disappeared from the San Francisco Bay, and scientists need a clearer picture of its original species composition—which was never properly documented. With that insight, conservation research groups like the San Francisco Bay Bird Observatory can help guide best practices when restoring the native habitat that has long served as critical refuge for imperiled birds and animals as adjacent marshes flood more with rising sea levels. “We can’t ask restoration ecologists to plant nonnative species or to just take their best guess and throw things out there,” says Rinkert.',\n",
       " 'prompt_id': '627a77298cf96a309aa35a62207c4164e22a66f6db79119506228f28ddc0f947',\n",
       " 'messages': [{'content': 'Please summarize the goals for scientists in this text:\\n\\nWithin three days, the intertwined cup nest of grasses was complete, featuring a canopy of overhanging grasses to conceal it. And decades later, it served as Rinkert’s portal to the past inside the California Academy of Sciences. Information gleaned from such nests, woven long ago from species in plant communities called transitional habitat, could help restore the shoreline in the future. Transitional habitat has nearly disappeared from the San Francisco Bay, and scientists need a clearer picture of its original species composition—which was never properly documented. With that insight, conservation research groups like the San Francisco Bay Bird Observatory can help guide best practices when restoring the native habitat that has long served as critical refuge for imperiled birds and animals as adjacent marshes flood more with rising sea levels. “We can’t ask restoration ecologists to plant nonnative species or to just take their best guess and throw things out there,” says Rinkert.',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Scientists are studying nests hoping to learn about transitional habitats that could help restore the shoreline of San Francisco Bay.',\n",
       "   'role': 'assistant'}],\n",
       " 'category': 'Summarize'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6190e2927bd84be6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
