{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RLHF Demo\n",
    "Run post training on a pretrained GPT-2 model to understand RLHF. Steps will be SFT -> train reward model -> run grpo on pretrained llm on reward model. Rather than using TRL, I will be implementing grpo myself. Implementation will start with single gpu and then scaled to distributed system."
   ],
   "id": "6a402223a4106937"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T21:36:28.308800Z",
     "start_time": "2025-08-21T21:36:06.199665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.eval()\n",
    "\n",
    "prompt = \"The usual weather in California is\"\n",
    "inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=1000,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ],
   "id": "a36fde68ad87b98c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The usual weather in California is a bit of a mess.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but the clouds are still thick.\n",
      "\n",
      "The sun is shining, but\n"
     ]
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Supervised fine tuning\n",
    "\n",
    "What I need to do:\n",
    "1. Preprocess data into chat template with EOS token. Ensure data is padded and make sure batches are truncated to fit context length.\n",
    "2. Iterate through every batch and for each one calculate the loss (ONLY on the last assistant completion so the model learns prompt prediction). We use cross entropy btw.\n",
    "3. Run a number of epochs on it.\n",
    "4. Keep single threaded till we implement grpo as well."
   ],
   "id": "fb9e9f51ec732eb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T23:29:11.647253Z",
     "start_time": "2025-08-21T23:29:01.865137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset, load_dataset_builder, get_dataset_split_names\n",
    "from torch.utils.data import DataLoader\n",
    "from pprint import pprint\n",
    "import copy\n",
    "\n",
    "# ---------------\n",
    "# hyperparameters / config\n",
    "num_epochs = 5\n",
    "batch_size = 2\n",
    "lr = 5e-5\n",
    "weight_decay = 0.01\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# ---------------\n",
    "\n",
    "# create dataset train/val/test splits\n",
    "train_sft_dataset = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split='train_sft').select(range(1000))\n",
    "train_split_size = int(0.9 * len(train_sft_dataset))\n",
    "train_split = train_sft_dataset.select(range(train_split_size))\n",
    "val_split = train_sft_dataset.select(range(train_split_size, len(train_sft_dataset)))\n",
    "\n",
    "# create chat template for tokenizer to use, gpt2 uses eos token so we need to add that as well\n",
    "tokenizer.chat_template = \"\"\"\n",
    "{%- for message in messages %}\n",
    "    {{- '<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n' }}\n",
    "{%- endfor %}\n",
    "{%- if add_generation_prompt %}\n",
    "    {{- '<|im_start|>assistant\\n' }}\n",
    "{%- else %}\n",
    "    {{- eos_token }}\n",
    "{%- endif %}\n",
    "\"\"\"\n",
    "\n",
    "# preprocess data and create dataloader\n",
    "def truncate_prompt(prompt):\n",
    "    max_context_length = model.config.max_position_embeddings\n",
    "    # while True:\n",
    "    #     enc_chat_tem_ex\n",
    "\n",
    "\n",
    "ending_msg_token_len = len(tokenizer.encode('<|im_end|>\\n'))\n",
    "def add_chat_tem(example):\n",
    "    # truncate conversations by message boundary\n",
    "    # truncation strategy:\n",
    "    # 1. remove entire user/assistant pairs until it fits context window in fifo order but keep system prompt\n",
    "    # 2. if you have one left, and it still isn't fitting into the context window, remove the tokens till it does\n",
    "    example['og_messages'] = copy.deepcopy(example['messages'])\n",
    "    max_context_length = model.config.max_position_embeddings\n",
    "    has_system = 1 if example['messages'][0]['role'] == 'system' else 0\n",
    "    enc_chat_tem_ex = tokenizer.apply_chat_template(example['messages'], tokenize=True, add_special_tokens=False)\n",
    "    while True:\n",
    "        diff = len(enc_chat_tem_ex) - max_context_length\n",
    "        if diff <= 0:\n",
    "            example['exclude'] = False\n",
    "            break\n",
    "        elif len(example['messages']) // 2 <= 1:\n",
    "            example['exclude'] = True\n",
    "            break\n",
    "\n",
    "        del example['messages'][0 + has_system]\n",
    "        del example['messages'][0 + has_system]\n",
    "\n",
    "\n",
    "    # convert to chat template and keep track of # of tokens in last generation\n",
    "    enc_chat_tem_ex = tokenizer.apply_chat_template(example['messages'], tokenize=True, add_special_tokens=False)\n",
    "    example['input_ids'] = enc_chat_tem_ex\n",
    "    end_size = (len(tokenizer.encode(example['messages'][-1]['content'], add_special_tokens=False)) + ending_msg_token_len)\n",
    "    last_gen_start_ind = len(enc_chat_tem_ex) - end_size\n",
    "    example['last_gen_start_ind'] = last_gen_start_ind\n",
    "    return example\n",
    "\n",
    "exclude_filter = lambda x: x['exclude']\n",
    "train_split = train_split.map(add_chat_tem).filter(exclude_filter)\n",
    "val_split = val_split.map(add_chat_tem).filter(exclude_filter)\n",
    "\n",
    "# create custom collator for sft\n",
    "class DataCollatorForSFT(DataCollatorForLanguageModeling):\n",
    "    def __call__(self, features, return_tensors=None):\n",
    "        last_gen_start_inds = [example['last_gen_start_ind'] for example in features]\n",
    "        features = [{'input_ids': example['input_ids']} for example in features]\n",
    "        batch = super().__call__(features, return_tensors=return_tensors)\n",
    "        # scrappy but just assume we're calling with return_tensors='pt'\n",
    "        batch['last_gen_start_inds'] = torch.tensor(last_gen_start_inds)\n",
    "\n",
    "        return batch\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForSFT(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_split,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator\n",
    ")"
   ],
   "id": "b8e444928958616b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 900/900 [00:05<00:00, 153.92 examples/s]\n",
      "Filter: 100%|██████████| 900/900 [00:00<00:00, 7415.66 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 128.43 examples/s]\n",
      "Filter: 100%|██████████| 100/100 [00:00<00:00, 6477.49 examples/s]\n"
     ]
    }
   ],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T23:29:13.880689Z",
     "start_time": "2025-08-21T23:29:13.870316Z"
    }
   },
   "cell_type": "code",
   "source": "pprint(train_split[0])",
   "id": "6ed83db81e20cf58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exclude': True,\n",
      " 'input_ids': [27,\n",
      "               91,\n",
      "               320,\n",
      "               62,\n",
      "               9688,\n",
      "               91,\n",
      "               29,\n",
      "               7220,\n",
      "               198,\n",
      "               40,\n",
      "               460,\n",
      "               470,\n",
      "               4043,\n",
      "               284,\n",
      "               766,\n",
      "               326,\n",
      "               4017,\n",
      "               23151,\n",
      "               379,\n",
      "               262,\n",
      "               31096,\n",
      "               12958,\n",
      "               358,\n",
      "               9594,\n",
      "               13,\n",
      "               314,\n",
      "               4240,\n",
      "               611,\n",
      "               340,\n",
      "               338,\n",
      "               1103,\n",
      "               393,\n",
      "               655,\n",
      "               257,\n",
      "               30069,\n",
      "               13,\n",
      "               15467,\n",
      "               835,\n",
      "               11,\n",
      "               340,\n",
      "               338,\n",
      "               5421,\n",
      "               284,\n",
      "               307,\n",
      "               257,\n",
      "               13899,\n",
      "               2378,\n",
      "               284,\n",
      "               23700,\n",
      "               13,\n",
      "               843,\n",
      "               314,\n",
      "               1183,\n",
      "               787,\n",
      "               1654,\n",
      "               284,\n",
      "               1502,\n",
      "               326,\n",
      "               366,\n",
      "               44,\n",
      "               7780,\n",
      "               1698,\n",
      "               21759,\n",
      "               1,\n",
      "               24554,\n",
      "               981,\n",
      "               314,\n",
      "               1101,\n",
      "               612,\n",
      "               0,\n",
      "               27,\n",
      "               91,\n",
      "               320,\n",
      "               62,\n",
      "               437,\n",
      "               91,\n",
      "               29,\n",
      "               198,\n",
      "               27,\n",
      "               91,\n",
      "               320,\n",
      "               62,\n",
      "               9688,\n",
      "               91,\n",
      "               29,\n",
      "               562,\n",
      "               10167,\n",
      "               198,\n",
      "               5297,\n",
      "               11,\n",
      "               262,\n",
      "               4017,\n",
      "               23151,\n",
      "               379,\n",
      "               262,\n",
      "               31096,\n",
      "               12958,\n",
      "               358,\n",
      "               9594,\n",
      "               286,\n",
      "               4424,\n",
      "               4267,\n",
      "               871,\n",
      "               318,\n",
      "               4753,\n",
      "               530,\n",
      "               286,\n",
      "               663,\n",
      "               749,\n",
      "               5863,\n",
      "               27508,\n",
      "               13,\n",
      "               632,\n",
      "               338,\n",
      "               1682,\n",
      "               257,\n",
      "               27702,\n",
      "               925,\n",
      "               422,\n",
      "               262,\n",
      "               18328,\n",
      "               286,\n",
      "               257,\n",
      "               21657,\n",
      "               290,\n",
      "               262,\n",
      "               7894,\n",
      "               286,\n",
      "               257,\n",
      "               5916,\n",
      "               11,\n",
      "               523,\n",
      "               340,\n",
      "               338,\n",
      "               407,\n",
      "               257,\n",
      "               1103,\n",
      "               4017,\n",
      "               23151,\n",
      "               286,\n",
      "               1781,\n",
      "               11,\n",
      "               475,\n",
      "               340,\n",
      "               338,\n",
      "               991,\n",
      "               281,\n",
      "               19827,\n",
      "               3704,\n",
      "               13,\n",
      "               383,\n",
      "               13257,\n",
      "               468,\n",
      "               867,\n",
      "               584,\n",
      "               1090,\n",
      "               4267,\n",
      "               871,\n",
      "               284,\n",
      "               7073,\n",
      "               355,\n",
      "               880,\n",
      "               11,\n",
      "               290,\n",
      "               262,\n",
      "               8137,\n",
      "               612,\n",
      "               318,\n",
      "               5023,\n",
      "               1997,\n",
      "               345,\n",
      "               1183,\n",
      "               1064,\n",
      "               287,\n",
      "               584,\n",
      "               30794,\n",
      "               13,\n",
      "               843,\n",
      "               836,\n",
      "               470,\n",
      "               6044,\n",
      "               284,\n",
      "               1949,\n",
      "               326,\n",
      "               366,\n",
      "               44,\n",
      "               7780,\n",
      "               1698,\n",
      "               21759,\n",
      "               1,\n",
      "               24554,\n",
      "               532,\n",
      "               340,\n",
      "               338,\n",
      "               262,\n",
      "               2818,\n",
      "               10600,\n",
      "               3681,\n",
      "               284,\n",
      "               262,\n",
      "               13257,\n",
      "               338,\n",
      "               37276,\n",
      "               27426,\n",
      "               0,\n",
      "               27,\n",
      "               91,\n",
      "               320,\n",
      "               62,\n",
      "               437,\n",
      "               91,\n",
      "               29,\n",
      "               198,\n",
      "               50256],\n",
      " 'last_gen_start_ind': 89,\n",
      " 'messages': [{'content': \"I can't wait to see that mermaid at the Viktor Wynd \"\n",
      "                          \"Museum. I wonder if it's real or just a replica. \"\n",
      "                          \"Either way, it's bound to be a fascinating item to \"\n",
      "                          'behold. And I\\'ll make sure to order that \"Mermaid '\n",
      "                          'Tail\" cocktail while I\\'m there!',\n",
      "               'role': 'user'},\n",
      "              {'content': 'Yes, the mermaid at the Viktor Wynd Museum of '\n",
      "                          'Curiosities is definitely one of its most famous '\n",
      "                          \"exhibits. It's actually a recreation made from the \"\n",
      "                          'skeleton of a monkey and the tail of a fish, so '\n",
      "                          \"it's not a real mermaid of course, but it's still \"\n",
      "                          'an intriguing piece. The museum has many other '\n",
      "                          'curiosities to discover as well, and the atmosphere '\n",
      "                          \"there is unlike anything you'll find in other \"\n",
      "                          'museums. And don\\'t forget to try that \"Mermaid '\n",
      "                          'Tail\" cocktail - it\\'s the perfect accompaniment to '\n",
      "                          \"the museum's quirky vibe!\",\n",
      "               'role': 'assistant'}],\n",
      " 'og_messages': [{'content': 'Which famous landmarks should I visit in London, '\n",
      "                             'beyond the usual ones?',\n",
      "                  'role': 'user'},\n",
      "                 {'content': '1. Leadenhall Market - a beautiful indoor market '\n",
      "                             'with stunning Victorian architecture, also used '\n",
      "                             'as a filming location in the Harry Potter '\n",
      "                             'films.\\n'\n",
      "                             '\\n'\n",
      "                             '2. St. Dunstan in the East - a ruined church in '\n",
      "                             'the middle of the city that has been turned into '\n",
      "                             'a beautiful public garden.\\n'\n",
      "                             '\\n'\n",
      "                             '3. The Monument - a 202-foot-tall column '\n",
      "                             'commemorating the Great Fire of London, with a '\n",
      "                             'staircase leading to a viewing platform offering '\n",
      "                             'great views of the city.\\n'\n",
      "                             '\\n'\n",
      "                             '4. The Camden Town Markets - an eclectic '\n",
      "                             'collection of markets offering food, fashion, '\n",
      "                             'and vintage items, plus live music and street '\n",
      "                             'performers.\\n'\n",
      "                             '\\n'\n",
      "                             \"5. Novelist's House - the former home of Charles \"\n",
      "                             'Dickens, now a museum dedicated to his life and '\n",
      "                             'works.\\n'\n",
      "                             '\\n'\n",
      "                             '6. The Old Operating Theatre - a museum housed '\n",
      "                             'in the oldest surviving operating theatre in '\n",
      "                             'Europe, with exhibits on the history of surgery '\n",
      "                             'and medical practices.\\n'\n",
      "                             '\\n'\n",
      "                             '7. The Churchill War Rooms - an underground '\n",
      "                             'complex used as a British government command '\n",
      "                             'centre during World War II, now a museum '\n",
      "                             'dedicated to Winston Churchill and his '\n",
      "                             'leadership during the war.\\n'\n",
      "                             '\\n'\n",
      "                             '8. The Brunel Museum - a museum dedicated to the '\n",
      "                             'life and works of engineer Isambard Kingdom '\n",
      "                             'Brunel, with exhibitions on his revolutionary '\n",
      "                             'designs for bridges, ships, and tunnels.\\n'\n",
      "                             '\\n'\n",
      "                             '9. The Clink Prison Museum - a museum in the '\n",
      "                             'former site of the notorious medieval prison, '\n",
      "                             'with exhibits on the history of crime and '\n",
      "                             'punishment in London.\\n'\n",
      "                             '\\n'\n",
      "                             '10. The Royal Observatory Greenwich - an '\n",
      "                             'observatory and museum dedicated to astronomy '\n",
      "                             'and navigation, with exhibits on the history of '\n",
      "                             'timekeeping and space exploration.',\n",
      "                  'role': 'assistant'},\n",
      "                 {'content': \"Hmm, those are interesting suggestions, but I've \"\n",
      "                             'already seen so many touristy landmarks in '\n",
      "                             'London. Is there something more offbeat that you '\n",
      "                             'can recommend? Something that locals might know '\n",
      "                             'about?',\n",
      "                  'role': 'user'},\n",
      "                 {'content': 'Absolutely! Here are some offbeat and '\n",
      "                             'lesser-known things to see in London that locals '\n",
      "                             'might recommend:\\n'\n",
      "                             '\\n'\n",
      "                             \"1. God's Own Junkyard - a neon wonderland filled \"\n",
      "                             'with vintage and new neon signs.\\n'\n",
      "                             '\\n'\n",
      "                             '2. Hornsey Town Hall Arts Centre - a grade II '\n",
      "                             'listed building with a rich history and home to '\n",
      "                             'many art exhibitions and events.\\n'\n",
      "                             '\\n'\n",
      "                             '3. Clapham Grand - a historic Victorian theatre '\n",
      "                             'that has been transformed into a music venue, '\n",
      "                             'cinema and a comedy club.\\n'\n",
      "                             '\\n'\n",
      "                             '4. Gordon Museum of Pathology - the pathology '\n",
      "                             \"museum of King's College in London that holds a \"\n",
      "                             'collection of over 8,000 medical specimens.\\n'\n",
      "                             '\\n'\n",
      "                             \"5. John Soane's Museum - the former home of \"\n",
      "                             'wealthy architect John Soane is a museum with '\n",
      "                             'eclectic collections of paintings, sculptures, '\n",
      "                             'and curiosities.\\n'\n",
      "                             '\\n'\n",
      "                             '6. The Viktor Wynd Museum of Curiosities - a '\n",
      "                             'small museum filled with strange and unusual '\n",
      "                             'objects, taxidermy, and rare books.\\n'\n",
      "                             '\\n'\n",
      "                             '7. The Cross Bones Graveyard - a medieval '\n",
      "                             'graveyard that became known as an outcast '\n",
      "                             'cemetery with a history connected to the sex '\n",
      "                             'industry, now a memorial garden.\\n'\n",
      "                             '\\n'\n",
      "                             '8. Highgate Cemetery - a beautiful Victorian '\n",
      "                             'graveyard known for its Gothic architecture and '\n",
      "                             'where many famous people, including Karl Marx, '\n",
      "                             'are buried.\\n'\n",
      "                             '\\n'\n",
      "                             '9. Dalston Eastern Curve Garden - a beautiful '\n",
      "                             'community garden near the Dalston Junction '\n",
      "                             'station that is run by volunteers and has '\n",
      "                             'regular events.\\n'\n",
      "                             '\\n'\n",
      "                             '10. The Geffrye Museum of the Home - a museum '\n",
      "                             'that explores the history of domestic interiors '\n",
      "                             'in England, with a beautiful garden and regular '\n",
      "                             'market events.\\n'\n",
      "                             '\\n'\n",
      "                             'There are many other hidden gems in London, and '\n",
      "                             'a quick Google search for ‘offbeat things in '\n",
      "                             'London’ will bring up many blogs and resources '\n",
      "                             'with more options.',\n",
      "                  'role': 'assistant'},\n",
      "                 {'content': 'Wow, these offbeat suggestions are really '\n",
      "                             'interesting. I had no idea there were so many '\n",
      "                             'unique things to see in London. Thanks for the '\n",
      "                             \"recommendations, you're much more helpful than I \"\n",
      "                             'expected. Can you tell me more about the Viktor '\n",
      "                             'Wynd Museum of Curiosities? It sounds like my '\n",
      "                             'kind of place.',\n",
      "                  'role': 'user'},\n",
      "                 {'content': 'Sure! The Viktor Wynd Museum of Curiosities, '\n",
      "                             'Fine Art & Natural History is a small museum '\n",
      "                             'located in Hackney, East London. The museum, '\n",
      "                             'founded by collector Viktor Wynd is a place '\n",
      "                             'where you can find taxidermy, books, anatomical '\n",
      "                             'models, and other curiosities. The museum is '\n",
      "                             'famous for its collection of shrunken heads, '\n",
      "                             'dodo bones, and the famous mermaid. It is also '\n",
      "                             'notable for its dimly lit, atmospheric decor, '\n",
      "                             'and its bar which serves cocktails and allows '\n",
      "                             'visitors to take drinks into the museum. The '\n",
      "                             'museum is open daily except for Mondays and '\n",
      "                             'Tuesdays, and it also frequently hosts events '\n",
      "                             'and exhibitions, so be sure to check the '\n",
      "                             \"museum's website to see what's on.\",\n",
      "                  'role': 'assistant'},\n",
      "                 {'content': 'Woah, the Viktor Wynd Museum sounds like a wacky '\n",
      "                             \"and fun place to visit. I don't think I've ever \"\n",
      "                             'seen a shrunken head before. I wonder what kind '\n",
      "                             'of cocktails they serve there... Maybe I can '\n",
      "                             'convince some friends to check it out with me!',\n",
      "                  'role': 'user'},\n",
      "                 {'content': 'Yes, the museum is definitely one of the more '\n",
      "                             'unusual places to visit in London! The cocktail '\n",
      "                             \"menu at Viktor Wynd's bar is just as eclectic as \"\n",
      "                             \"the museum's collection, featuring brightly \"\n",
      "                             'colored cocktails inspired by the exhibits, such '\n",
      "                             'as the \"Shrunken Head\" or \"Mermaid Tail\" '\n",
      "                             'cocktails. The museum and bar are on the smaller '\n",
      "                             'side, so it would make for a unique and intimate '\n",
      "                             \"outing with friends. If you're looking for \"\n",
      "                             'something different and memorable to do in '\n",
      "                             'London, the Viktor Wynd Museum is definitely '\n",
      "                             'worth checking out!',\n",
      "                  'role': 'assistant'},\n",
      "                 {'content': \"Whoa, a bar in a museum?! That's wild. I'm \"\n",
      "                             'definitely going to have to try one of those '\n",
      "                             'cocktails. Do you think they have anything with '\n",
      "                             'a shrunken head as a garnish? That would be a '\n",
      "                             'trip.',\n",
      "                  'role': 'user'},\n",
      "                 {'content': 'I am not sure if the Viktor Wynd Museum of '\n",
      "                             'Curiosities serves cocktails with an actual '\n",
      "                             'shrunken head as a garnish. However, they might '\n",
      "                             'have some creative cocktails that incorporate a '\n",
      "                             'shrunken head replica or something similar as an '\n",
      "                             'element in the drink. Nevertheless, the bar '\n",
      "                             'offers a unique setting and a cocktail menu that '\n",
      "                             \"includes some unusual ingredients so it's \"\n",
      "                             \"definitely worth checking out! It's likely to be \"\n",
      "                             \"an eccentric and memorable experience, and I'm \"\n",
      "                             \"sure you'll have a great time there with your \"\n",
      "                             'friends.',\n",
      "                  'role': 'assistant'},\n",
      "                 {'content': \"I can't wait to see that mermaid at the Viktor \"\n",
      "                             \"Wynd Museum. I wonder if it's real or just a \"\n",
      "                             \"replica. Either way, it's bound to be a \"\n",
      "                             \"fascinating item to behold. And I'll make sure \"\n",
      "                             'to order that \"Mermaid Tail\" cocktail while I\\'m '\n",
      "                             'there!',\n",
      "                  'role': 'user'},\n",
      "                 {'content': 'Yes, the mermaid at the Viktor Wynd Museum of '\n",
      "                             'Curiosities is definitely one of its most famous '\n",
      "                             \"exhibits. It's actually a recreation made from \"\n",
      "                             'the skeleton of a monkey and the tail of a fish, '\n",
      "                             \"so it's not a real mermaid of course, but it's \"\n",
      "                             'still an intriguing piece. The museum has many '\n",
      "                             'other curiosities to discover as well, and the '\n",
      "                             \"atmosphere there is unlike anything you'll find \"\n",
      "                             \"in other museums. And don't forget to try that \"\n",
      "                             '\"Mermaid Tail\" cocktail - it\\'s the perfect '\n",
      "                             \"accompaniment to the museum's quirky vibe!\",\n",
      "                  'role': 'assistant'}],\n",
      " 'prompt': 'Which famous landmarks should I visit in London, beyond the usual '\n",
      "           'ones?',\n",
      " 'prompt_id': 'f5025bdcae61bb77fd98a4d6cd6ba8e0199a098cfebcf6830f4a85e0d13a9e21'}\n"
     ]
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T21:39:35.731344Z",
     "start_time": "2025-08-21T21:39:35.577984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "BxT -> BxTxP\n",
    "A couple of issues I need to work out:\n",
    "1. Padding inputs_ids in each prompt in the match correctly and ensuring attention mask is right\n",
    "2. After we feed the prompt, we need to remove everything but the corresponding amount of tokens from the end of the prompt corresponding to the last assistant generation. We need to calculate labels that way simimlarly.\n",
    "3. Calculate the loss for the sliced part (but each batch inner matrix is different size so need to think about that).\n",
    "4. Backprop on that to train the model.\n",
    "'''\n",
    "\n",
    "# training run\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        labels = batch['labels']\n",
    "        last_gen_start_inds = batch['last_gen_start_inds']\n",
    "        attention_mask = batch['attention_mask']\n",
    "\n",
    "        print(\"INPUT IDS SHAPE:\")\n",
    "        print(input_ids.shape)\n",
    "        print(\"MAX:\", input_ids.max())\n",
    "        print(\"MIN:\", input_ids.min())\n",
    "\n",
    "        # Debug tokenizer\n",
    "        print(f\"Tokenizer class: {type(tokenizer)}\")\n",
    "        print(f\"Tokenizer vocab size: {len(tokenizer)}\")\n",
    "        print(f\"Pad token: {tokenizer.pad_token}\")\n",
    "        print(f\"Pad token ID: {tokenizer.pad_token_id}\")\n",
    "        print(f\"EOS token ID: {tokenizer.eos_token_id}\")\n",
    "        print(f\"Max position embeddings: {model.config.max_position_embeddings}\")\n",
    "        print(f\"Model context window: {getattr(model.config, 'n_positions', 'Not specified')}\")\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "        # Check if pad token was added correctly\n",
    "        if tokenizer.pad_token_id == 50256:  # This should match your max token\n",
    "            print(\"Pad token ID matches max token - this is likely the issue!\")\n",
    "\n",
    "        # print(\"shape:\", input_ids.shape)\n",
    "        #\n",
    "        # print(\"\\n\\n\\n\\n\")\n",
    "        #\n",
    "        # first_prompt_input_ids = batch['input_ids'][0]\n",
    "        # print(len(first_prompt_input_ids))\n",
    "        # first_prompt_last_gen_token_len = batch['last_gen_start_inds'][0].item()\n",
    "        # print(first_prompt_last_gen_token_len)\n",
    "        #\n",
    "        # print(\"\\n\\n\\n\\n\")\n",
    "        # print(tokenizer.decode(first_prompt_input_ids[:first_prompt_last_gen_token_len]))\n",
    "        #\n",
    "        #\n",
    "        # mask labels that aren't included in last gen\n",
    "        mask = torch.arange(input_ids.shape[1]) < last_gen_start_inds[:, None]\n",
    "        # print(\"\\n\\n\\n\\n\")\n",
    "        # print(mask)\n",
    "        labels[mask] = -100\n",
    "        # print(labels)\n",
    "\n",
    "        # run forward pass and calc loss\n",
    "        model_outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # print(model_outputs.logits.shape)\n",
    "\n",
    "\n",
    "        break\n",
    "    break"
   ],
   "id": "71d7c703271a5893",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT IDS SHAPE:\n",
      "torch.Size([2, 1130])\n",
      "MAX: tensor(50256)\n",
      "MIN: tensor(11)\n",
      "Tokenizer class: <class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>\n",
      "Tokenizer vocab size: 50257\n",
      "Pad token: <|endoftext|>\n",
      "Pad token ID: 50256\n",
      "EOS token ID: 50256\n",
      "Max position embeddings: 1024\n",
      "Model max length: 20\n",
      "Model context window: 1024\n",
      "Pad token ID matches max token - this is likely the issue!\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[173]\u001B[39m\u001B[32m, line 59\u001B[39m\n\u001B[32m     55\u001B[39m labels[mask] = -\u001B[32m100\u001B[39m\n\u001B[32m     56\u001B[39m \u001B[38;5;66;03m# print(labels)\u001B[39;00m\n\u001B[32m     57\u001B[39m \n\u001B[32m     58\u001B[39m \u001B[38;5;66;03m# run forward pass and calc loss\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m model_outputs = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[38;5;66;03m# print(model_outputs.logits.shape)\u001B[39;00m\n\u001B[32m     63\u001B[39m \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1076\u001B[39m, in \u001B[36mGPT2LMHeadModel.forward\u001B[39m\u001B[34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **kwargs)\u001B[39m\n\u001B[32m   1056\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1057\u001B[39m \u001B[33;03minput_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\u001B[39;00m\n\u001B[32m   1058\u001B[39m \u001B[33;03m    `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1072\u001B[39m \u001B[33;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001B[39;00m\n\u001B[32m   1073\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1074\u001B[39m return_dict = return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.use_return_dict\n\u001B[32m-> \u001B[39m\u001B[32m1076\u001B[39m transformer_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1077\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1078\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1079\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1080\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1081\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1082\u001B[39m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1083\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1084\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1085\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1086\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1087\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1088\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1089\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1090\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1091\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1092\u001B[39m hidden_states = transformer_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m   1094\u001B[39m \u001B[38;5;66;03m# Set device for model parallelism\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:867\u001B[39m, in \u001B[36mGPT2Model.forward\u001B[39m\u001B[34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001B[39m\n\u001B[32m    864\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m position_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    865\u001B[39m     position_ids = cache_position.unsqueeze(\u001B[32m0\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m867\u001B[39m position_embeds = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mwpe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    868\u001B[39m hidden_states = inputs_embeds + position_embeds.to(inputs_embeds.device)\n\u001B[32m    870\u001B[39m \u001B[38;5;66;03m# Attention mask.\u001B[39;00m\n\u001B[32m    871\u001B[39m \u001B[38;5;66;03m# ._update_causal_mask() and ._prepare_4d_causal_attention_mask_with_cache_position() copied from LlamaModel\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py:190\u001B[39m, in \u001B[36mEmbedding.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    189\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m190\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    191\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    192\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    193\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    194\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    195\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    196\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    197\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    198\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/functional.py:2551\u001B[39m, in \u001B[36membedding\u001B[39m\u001B[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[39m\n\u001B[32m   2545\u001B[39m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[32m   2546\u001B[39m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[32m   2547\u001B[39m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[32m   2548\u001B[39m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[32m   2549\u001B[39m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[32m   2550\u001B[39m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[32m-> \u001B[39m\u001B[32m2551\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mIndexError\u001B[39m: index out of range in self"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create the reward model",
   "id": "6e77f8f5907b1bc8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T19:41:25.928628Z",
     "start_time": "2025-08-20T19:41:25.919996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The reward model generates a single logit representing the probability of that response (we use Bradley-Terry model of preferences)\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, input_size * 4)\n",
    "        self.fc2 = nn.Linear(input_size * 4, 1)\n",
    "\n",
    "'''\n",
    "Preference training loop steps:\n",
    "1. Iterate through synthetic data of preferences.\n",
    "2. Use the final hidden state last embedding as input to reward network.\n",
    "3. Do that for both (otherwise you can use synthetic data and feed into the network the prompt + the response)\n",
    "4. Use that to get the embeddings for both (just do one pass)\n",
    "5. Calculate the loss based on Bradley-Terry and do backprop on the reward model network (you can mean the sums so you do it batchwise)\n",
    "\n",
    "The idea we'll use is take the prompt reward string to get rewrd but only train on prompt to avoid mismatch problem.\n",
    "'''\n"
   ],
   "id": "daf721071ca1e02e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPreference training loop steps:\\n1. Iterate through synthetic data of preferences.\\n2. Use the final hidden state last embedding as input to reward network.\\n3. Do that for both (otherwise you can use synthetic data and feed into the network the prompt + the response)\\n4. Use that to get the embeddings for both (just do one pass)\\n5. Calculate the loss based on Bradley-Terry and do backprop on the reward model network (you can mean the sums so you do it batchwise)\\n\\nThe idea we'll use is take the prompt reward string to get rewrd but only train on prompt to avoid mismatch problem.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T19:58:32.609858Z",
     "start_time": "2025-08-20T19:58:31.662841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_data = load_dataset('HuggingFaceH4/no_robots')['train']\n",
    "train_data[0]"
   ],
   "id": "d09fc1eced2f7d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Please summarize the goals for scientists in this text:\\n\\nWithin three days, the intertwined cup nest of grasses was complete, featuring a canopy of overhanging grasses to conceal it. And decades later, it served as Rinkert’s portal to the past inside the California Academy of Sciences. Information gleaned from such nests, woven long ago from species in plant communities called transitional habitat, could help restore the shoreline in the future. Transitional habitat has nearly disappeared from the San Francisco Bay, and scientists need a clearer picture of its original species composition—which was never properly documented. With that insight, conservation research groups like the San Francisco Bay Bird Observatory can help guide best practices when restoring the native habitat that has long served as critical refuge for imperiled birds and animals as adjacent marshes flood more with rising sea levels. “We can’t ask restoration ecologists to plant nonnative species or to just take their best guess and throw things out there,” says Rinkert.',\n",
       " 'prompt_id': '627a77298cf96a309aa35a62207c4164e22a66f6db79119506228f28ddc0f947',\n",
       " 'messages': [{'content': 'Please summarize the goals for scientists in this text:\\n\\nWithin three days, the intertwined cup nest of grasses was complete, featuring a canopy of overhanging grasses to conceal it. And decades later, it served as Rinkert’s portal to the past inside the California Academy of Sciences. Information gleaned from such nests, woven long ago from species in plant communities called transitional habitat, could help restore the shoreline in the future. Transitional habitat has nearly disappeared from the San Francisco Bay, and scientists need a clearer picture of its original species composition—which was never properly documented. With that insight, conservation research groups like the San Francisco Bay Bird Observatory can help guide best practices when restoring the native habitat that has long served as critical refuge for imperiled birds and animals as adjacent marshes flood more with rising sea levels. “We can’t ask restoration ecologists to plant nonnative species or to just take their best guess and throw things out there,” says Rinkert.',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Scientists are studying nests hoping to learn about transitional habitats that could help restore the shoreline of San Francisco Bay.',\n",
       "   'role': 'assistant'}],\n",
       " 'category': 'Summarize'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6190e2927bd84be6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
