{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### MLP setup and hyperparameters\n",
    "Setup hyperparameters and state tracking with simple MLP definition"
   ],
   "id": "9f0747e19293744a"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-05T01:36:47.695662Z",
     "start_time": "2025-08-05T01:36:47.688041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Steps:\n",
    "# 1. Create pytorch simple mlp model\n",
    "# 2. Implement dqn algorithm with mlp model\n",
    "# 3. Test algorithm in certain environment\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  def __init__(self, in_dim, out_dim):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(in_dim, 64)\n",
    "    self.fc2 = nn.Linear(64, 64)\n",
    "    self.fc3 = nn.Linear(64, out_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x\n",
    "\n",
    "# Using CartPole-v1 env, so 4 state vars + actions\n",
    "# We have discrete actions so for efficiently our MLP will output [Q(state, action_1), Q(state, action_2)]\n",
    "# We will one-hot-encode the input state\n",
    "\n",
    "# Implement DQN algorithm\n",
    "\n",
    "# Constants\n",
    "replay_cap = 10000\n",
    "obs_space_dim = 4\n",
    "action_space_dim = 2\n",
    "episodes = 600\n",
    "horizon = 500\n",
    "# Use linear epsilon decay to encourage high exploration in the beginning\n",
    "eps = 0.9\n",
    "eps_end = 0.01\n",
    "discount = 0.99\n",
    "C = 100\n",
    "minibatch_size = 64\n",
    "env = gym.make('CartPole-v1', render_mode='human', max_episode_steps=horizon)\n",
    "\n",
    "# Init replay memory with capacity replay_cap\n",
    "replay_mem = deque(maxlen=replay_cap)\n",
    "# Init action-value func Q w/ random weights\n",
    "q = MLP(4, 2)\n",
    "# Init target action-value func w/ random weights (separate selecting best action and updating val for training stabilization)\n",
    "q_hat = MLP(4, 2)\n",
    "# Init optimizer\n",
    "optimizer = torch.optim.AdamW(q.parameters(), lr=3e-4)\n",
    "# Init c counter\n",
    "c_step = 0\n",
    "# Init episode steps tracking\n",
    "episode_steps = []"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training run",
   "id": "8de9a214111d949a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T03:15:33.099427Z",
     "start_time": "2025-08-05T01:36:49.570897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Each episode represents how long we run through the env each time. This is different from the horizon which signifies how far ahead we're optimizing the reward path for (we assume infinite horizon)\n",
    "for episode in range(episodes):\n",
    "    # Init state\n",
    "    obs, _ = env.reset()\n",
    "    episode_over = False\n",
    "    step = 0\n",
    "\n",
    "    while not episode_over:\n",
    "        step += 1\n",
    "        # Get random action with prob eps or act greedily\n",
    "        obs = torch.tensor(obs, dtype=torch.float32)\n",
    "        if torch.rand(1) < eps:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            q_out = q(obs)\n",
    "            # We use q network to select action\n",
    "            action = torch.argmax(q(obs)).item()\n",
    "\n",
    "        # Execute action in emulator and observe reward and next state\n",
    "        obs_next, reward, terminated, truncated, _ = env.step(action)\n",
    "        episode_over = terminated or truncated\n",
    "\n",
    "        # Store new experience in replay memory\n",
    "        replay_mem.append((obs, action, reward, obs_next, episode_over))\n",
    "\n",
    "        # Sample random minibatch from replay mem\n",
    "        minibatch = random.sample(replay_mem, len(replay_mem) if len(replay_mem) < minibatch_size else minibatch_size)\n",
    "        y_j = torch.tensor([float(exp[2]) if exp[4] else float(exp[2]) + discount * torch.max(q_hat(torch.tensor(exp[3], dtype=torch.float32))).item() for exp in minibatch], dtype=torch.float32)\n",
    "\n",
    "        # Calculate loss and perform gradient descent step\n",
    "        q_vals = q(torch.stack([torch.tensor(exp[0]) for exp in minibatch]))\n",
    "        actions = torch.tensor([exp[1] for exp in minibatch])\n",
    "        q_vals = q_vals[torch.arange(len(minibatch)), actions]\n",
    "        loss = F.mse_loss(q_vals, y_j)\n",
    "\n",
    "        # Do only one gradient descent step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update state\n",
    "        obs = obs_next\n",
    "        c_step += 1\n",
    "\n",
    "        # Every C steps, copy weights from Q to Q_hat\n",
    "        if c_step % C == 0:\n",
    "            q_hat.load_state_dict(q.state_dict())\n",
    "\n",
    "    # Store episode steps\n",
    "    episode_steps.append(step)\n",
    "    print(f\"Finished episode {episode}, steps: {step}, eps: {eps}\")\n",
    "    eps = max(eps_end, eps - 0.004)\n",
    "\n",
    "print(\"Finished training\")\n",
    "\n",
    "env.close()"
   ],
   "id": "77e5a1dc037c21b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p6/sx805f6s2llg753msgs16xfr0000gn/T/ipykernel_32415/3534244343.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  q_vals = q(torch.stack([torch.tensor(exp[0]) for exp in minibatch]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode 0, steps: 11, eps: 0.9\n",
      "Finished episode 1, steps: 13, eps: 0.896\n",
      "Finished episode 2, steps: 24, eps: 0.892\n",
      "Finished episode 3, steps: 14, eps: 0.888\n",
      "Finished episode 4, steps: 22, eps: 0.884\n",
      "Finished episode 5, steps: 11, eps: 0.88\n",
      "Finished episode 6, steps: 16, eps: 0.876\n",
      "Finished episode 7, steps: 21, eps: 0.872\n",
      "Finished episode 8, steps: 12, eps: 0.868\n",
      "Finished episode 9, steps: 15, eps: 0.864\n",
      "Finished episode 10, steps: 21, eps: 0.86\n",
      "Finished episode 11, steps: 14, eps: 0.856\n",
      "Finished episode 12, steps: 11, eps: 0.852\n",
      "Finished episode 13, steps: 16, eps: 0.848\n",
      "Finished episode 14, steps: 24, eps: 0.844\n",
      "Finished episode 15, steps: 13, eps: 0.84\n",
      "Finished episode 16, steps: 15, eps: 0.836\n",
      "Finished episode 17, steps: 13, eps: 0.832\n",
      "Finished episode 18, steps: 57, eps: 0.828\n",
      "Finished episode 19, steps: 14, eps: 0.824\n",
      "Finished episode 20, steps: 11, eps: 0.82\n",
      "Finished episode 21, steps: 16, eps: 0.816\n",
      "Finished episode 22, steps: 14, eps: 0.8119999999999999\n",
      "Finished episode 23, steps: 13, eps: 0.8079999999999999\n",
      "Finished episode 24, steps: 14, eps: 0.8039999999999999\n",
      "Finished episode 25, steps: 11, eps: 0.7999999999999999\n",
      "Finished episode 26, steps: 15, eps: 0.7959999999999999\n",
      "Finished episode 27, steps: 20, eps: 0.7919999999999999\n",
      "Finished episode 28, steps: 15, eps: 0.7879999999999999\n",
      "Finished episode 29, steps: 10, eps: 0.7839999999999999\n",
      "Finished episode 30, steps: 20, eps: 0.7799999999999999\n",
      "Finished episode 31, steps: 24, eps: 0.7759999999999999\n",
      "Finished episode 32, steps: 16, eps: 0.7719999999999999\n",
      "Finished episode 33, steps: 31, eps: 0.7679999999999999\n",
      "Finished episode 34, steps: 8, eps: 0.7639999999999999\n",
      "Finished episode 35, steps: 12, eps: 0.7599999999999999\n",
      "Finished episode 36, steps: 10, eps: 0.7559999999999999\n",
      "Finished episode 37, steps: 16, eps: 0.7519999999999999\n",
      "Finished episode 38, steps: 44, eps: 0.7479999999999999\n",
      "Finished episode 39, steps: 15, eps: 0.7439999999999999\n",
      "Finished episode 40, steps: 32, eps: 0.7399999999999999\n",
      "Finished episode 41, steps: 16, eps: 0.7359999999999999\n",
      "Finished episode 42, steps: 28, eps: 0.7319999999999999\n",
      "Finished episode 43, steps: 19, eps: 0.7279999999999999\n",
      "Finished episode 44, steps: 12, eps: 0.7239999999999999\n",
      "Finished episode 45, steps: 22, eps: 0.7199999999999999\n",
      "Finished episode 46, steps: 19, eps: 0.7159999999999999\n",
      "Finished episode 47, steps: 16, eps: 0.7119999999999999\n",
      "Finished episode 48, steps: 39, eps: 0.7079999999999999\n",
      "Finished episode 49, steps: 12, eps: 0.7039999999999998\n",
      "Finished episode 50, steps: 36, eps: 0.6999999999999998\n",
      "Finished episode 51, steps: 59, eps: 0.6959999999999998\n",
      "Finished episode 52, steps: 27, eps: 0.6919999999999998\n",
      "Finished episode 53, steps: 23, eps: 0.6879999999999998\n",
      "Finished episode 54, steps: 28, eps: 0.6839999999999998\n",
      "Finished episode 55, steps: 13, eps: 0.6799999999999998\n",
      "Finished episode 56, steps: 22, eps: 0.6759999999999998\n",
      "Finished episode 57, steps: 23, eps: 0.6719999999999998\n",
      "Finished episode 58, steps: 21, eps: 0.6679999999999998\n",
      "Finished episode 59, steps: 48, eps: 0.6639999999999998\n",
      "Finished episode 60, steps: 46, eps: 0.6599999999999998\n",
      "Finished episode 61, steps: 32, eps: 0.6559999999999998\n",
      "Finished episode 62, steps: 28, eps: 0.6519999999999998\n",
      "Finished episode 63, steps: 27, eps: 0.6479999999999998\n",
      "Finished episode 64, steps: 19, eps: 0.6439999999999998\n",
      "Finished episode 65, steps: 11, eps: 0.6399999999999998\n",
      "Finished episode 66, steps: 48, eps: 0.6359999999999998\n",
      "Finished episode 67, steps: 43, eps: 0.6319999999999998\n",
      "Finished episode 68, steps: 56, eps: 0.6279999999999998\n",
      "Finished episode 69, steps: 57, eps: 0.6239999999999998\n",
      "Finished episode 70, steps: 39, eps: 0.6199999999999998\n",
      "Finished episode 71, steps: 45, eps: 0.6159999999999998\n",
      "Finished episode 72, steps: 85, eps: 0.6119999999999998\n",
      "Finished episode 73, steps: 55, eps: 0.6079999999999998\n",
      "Finished episode 74, steps: 31, eps: 0.6039999999999998\n",
      "Finished episode 75, steps: 118, eps: 0.5999999999999998\n",
      "Finished episode 76, steps: 79, eps: 0.5959999999999998\n",
      "Finished episode 77, steps: 40, eps: 0.5919999999999997\n",
      "Finished episode 78, steps: 105, eps: 0.5879999999999997\n",
      "Finished episode 79, steps: 22, eps: 0.5839999999999997\n",
      "Finished episode 80, steps: 81, eps: 0.5799999999999997\n",
      "Finished episode 81, steps: 97, eps: 0.5759999999999997\n",
      "Finished episode 82, steps: 102, eps: 0.5719999999999997\n",
      "Finished episode 83, steps: 32, eps: 0.5679999999999997\n",
      "Finished episode 84, steps: 22, eps: 0.5639999999999997\n",
      "Finished episode 85, steps: 109, eps: 0.5599999999999997\n",
      "Finished episode 86, steps: 43, eps: 0.5559999999999997\n",
      "Finished episode 87, steps: 15, eps: 0.5519999999999997\n",
      "Finished episode 88, steps: 155, eps: 0.5479999999999997\n",
      "Finished episode 89, steps: 148, eps: 0.5439999999999997\n",
      "Finished episode 90, steps: 107, eps: 0.5399999999999997\n",
      "Finished episode 91, steps: 92, eps: 0.5359999999999997\n",
      "Finished episode 92, steps: 201, eps: 0.5319999999999997\n",
      "Finished episode 93, steps: 39, eps: 0.5279999999999997\n",
      "Finished episode 94, steps: 135, eps: 0.5239999999999997\n",
      "Finished episode 95, steps: 204, eps: 0.5199999999999997\n",
      "Finished episode 96, steps: 311, eps: 0.5159999999999997\n",
      "Finished episode 97, steps: 59, eps: 0.5119999999999997\n",
      "Finished episode 98, steps: 53, eps: 0.5079999999999997\n",
      "Finished episode 99, steps: 82, eps: 0.5039999999999997\n",
      "Finished episode 100, steps: 37, eps: 0.49999999999999967\n",
      "Finished episode 101, steps: 237, eps: 0.49599999999999966\n",
      "Finished episode 102, steps: 81, eps: 0.49199999999999966\n",
      "Finished episode 103, steps: 149, eps: 0.48799999999999966\n",
      "Finished episode 104, steps: 225, eps: 0.48399999999999965\n",
      "Finished episode 105, steps: 20, eps: 0.47999999999999965\n",
      "Finished episode 106, steps: 118, eps: 0.47599999999999965\n",
      "Finished episode 107, steps: 181, eps: 0.47199999999999964\n",
      "Finished episode 108, steps: 322, eps: 0.46799999999999964\n",
      "Finished episode 109, steps: 17, eps: 0.46399999999999963\n",
      "Finished episode 110, steps: 292, eps: 0.45999999999999963\n",
      "Finished episode 111, steps: 77, eps: 0.45599999999999963\n",
      "Finished episode 112, steps: 57, eps: 0.4519999999999996\n",
      "Finished episode 113, steps: 380, eps: 0.4479999999999996\n",
      "Finished episode 114, steps: 203, eps: 0.4439999999999996\n",
      "Finished episode 115, steps: 187, eps: 0.4399999999999996\n",
      "Finished episode 116, steps: 252, eps: 0.4359999999999996\n",
      "Finished episode 117, steps: 296, eps: 0.4319999999999996\n",
      "Finished episode 118, steps: 349, eps: 0.4279999999999996\n",
      "Finished episode 119, steps: 248, eps: 0.4239999999999996\n",
      "Finished episode 120, steps: 52, eps: 0.4199999999999996\n",
      "Finished episode 121, steps: 310, eps: 0.4159999999999996\n",
      "Finished episode 122, steps: 53, eps: 0.4119999999999996\n",
      "Finished episode 123, steps: 103, eps: 0.4079999999999996\n",
      "Finished episode 124, steps: 212, eps: 0.4039999999999996\n",
      "Finished episode 125, steps: 279, eps: 0.3999999999999996\n",
      "Finished episode 126, steps: 207, eps: 0.3959999999999996\n",
      "Finished episode 127, steps: 100, eps: 0.39199999999999957\n",
      "Finished episode 128, steps: 57, eps: 0.38799999999999957\n",
      "Finished episode 129, steps: 123, eps: 0.38399999999999956\n",
      "Finished episode 130, steps: 240, eps: 0.37999999999999956\n",
      "Finished episode 131, steps: 244, eps: 0.37599999999999956\n",
      "Finished episode 132, steps: 168, eps: 0.37199999999999955\n",
      "Finished episode 133, steps: 277, eps: 0.36799999999999955\n",
      "Finished episode 134, steps: 236, eps: 0.36399999999999955\n",
      "Finished episode 135, steps: 231, eps: 0.35999999999999954\n",
      "Finished episode 136, steps: 258, eps: 0.35599999999999954\n",
      "Finished episode 137, steps: 181, eps: 0.35199999999999954\n",
      "Finished episode 138, steps: 121, eps: 0.34799999999999953\n",
      "Finished episode 139, steps: 53, eps: 0.34399999999999953\n",
      "Finished episode 140, steps: 127, eps: 0.3399999999999995\n",
      "Finished episode 141, steps: 137, eps: 0.3359999999999995\n",
      "Finished episode 142, steps: 227, eps: 0.3319999999999995\n",
      "Finished episode 143, steps: 215, eps: 0.3279999999999995\n",
      "Finished episode 144, steps: 207, eps: 0.3239999999999995\n",
      "Finished episode 145, steps: 218, eps: 0.3199999999999995\n",
      "Finished episode 146, steps: 216, eps: 0.3159999999999995\n",
      "Finished episode 147, steps: 347, eps: 0.3119999999999995\n",
      "Finished episode 148, steps: 207, eps: 0.3079999999999995\n",
      "Finished episode 149, steps: 255, eps: 0.3039999999999995\n",
      "Finished episode 150, steps: 228, eps: 0.2999999999999995\n",
      "Finished episode 151, steps: 279, eps: 0.2959999999999995\n",
      "Finished episode 152, steps: 355, eps: 0.2919999999999995\n",
      "Finished episode 153, steps: 217, eps: 0.2879999999999995\n",
      "Finished episode 154, steps: 188, eps: 0.2839999999999995\n",
      "Finished episode 155, steps: 270, eps: 0.27999999999999947\n",
      "Finished episode 156, steps: 252, eps: 0.27599999999999947\n",
      "Finished episode 157, steps: 195, eps: 0.27199999999999946\n",
      "Finished episode 158, steps: 226, eps: 0.26799999999999946\n",
      "Finished episode 159, steps: 278, eps: 0.26399999999999946\n",
      "Finished episode 160, steps: 121, eps: 0.25999999999999945\n",
      "Finished episode 161, steps: 226, eps: 0.25599999999999945\n",
      "Finished episode 162, steps: 258, eps: 0.25199999999999945\n",
      "Finished episode 163, steps: 217, eps: 0.24799999999999944\n",
      "Finished episode 164, steps: 208, eps: 0.24399999999999944\n",
      "Finished episode 165, steps: 190, eps: 0.23999999999999944\n",
      "Finished episode 166, steps: 227, eps: 0.23599999999999943\n",
      "Finished episode 167, steps: 202, eps: 0.23199999999999943\n",
      "Finished episode 168, steps: 190, eps: 0.22799999999999943\n",
      "Finished episode 169, steps: 271, eps: 0.22399999999999942\n",
      "Finished episode 170, steps: 200, eps: 0.21999999999999942\n",
      "Finished episode 171, steps: 253, eps: 0.21599999999999941\n",
      "Finished episode 172, steps: 183, eps: 0.2119999999999994\n",
      "Finished episode 173, steps: 301, eps: 0.2079999999999994\n",
      "Finished episode 174, steps: 238, eps: 0.2039999999999994\n",
      "Finished episode 175, steps: 200, eps: 0.1999999999999994\n",
      "Finished episode 176, steps: 201, eps: 0.1959999999999994\n",
      "Finished episode 177, steps: 202, eps: 0.1919999999999994\n",
      "Finished episode 178, steps: 226, eps: 0.1879999999999994\n",
      "Finished episode 179, steps: 231, eps: 0.1839999999999994\n",
      "Finished episode 180, steps: 308, eps: 0.17999999999999938\n",
      "Finished episode 181, steps: 251, eps: 0.17599999999999938\n",
      "Finished episode 182, steps: 256, eps: 0.17199999999999938\n",
      "Finished episode 183, steps: 234, eps: 0.16799999999999937\n",
      "Finished episode 184, steps: 247, eps: 0.16399999999999937\n",
      "Finished episode 185, steps: 263, eps: 0.15999999999999936\n",
      "Finished episode 186, steps: 210, eps: 0.15599999999999936\n",
      "Finished episode 187, steps: 225, eps: 0.15199999999999936\n",
      "Finished episode 188, steps: 192, eps: 0.14799999999999935\n",
      "Finished episode 189, steps: 232, eps: 0.14399999999999935\n",
      "Finished episode 190, steps: 196, eps: 0.13999999999999935\n",
      "Finished episode 191, steps: 193, eps: 0.13599999999999934\n",
      "Finished episode 192, steps: 312, eps: 0.13199999999999934\n",
      "Finished episode 193, steps: 223, eps: 0.12799999999999934\n",
      "Finished episode 194, steps: 189, eps: 0.12399999999999933\n",
      "Finished episode 195, steps: 225, eps: 0.11999999999999933\n",
      "Finished episode 196, steps: 215, eps: 0.11599999999999933\n",
      "Finished episode 197, steps: 229, eps: 0.11199999999999932\n",
      "Finished episode 198, steps: 293, eps: 0.10799999999999932\n",
      "Finished episode 199, steps: 208, eps: 0.10399999999999932\n",
      "Finished episode 200, steps: 213, eps: 0.09999999999999931\n",
      "Finished episode 201, steps: 294, eps: 0.09599999999999931\n",
      "Finished episode 202, steps: 228, eps: 0.0919999999999993\n",
      "Finished episode 203, steps: 255, eps: 0.0879999999999993\n",
      "Finished episode 204, steps: 218, eps: 0.0839999999999993\n",
      "Finished episode 205, steps: 322, eps: 0.0799999999999993\n",
      "Finished episode 206, steps: 492, eps: 0.07599999999999929\n",
      "Finished episode 207, steps: 275, eps: 0.07199999999999929\n",
      "Finished episode 208, steps: 335, eps: 0.06799999999999928\n",
      "Finished episode 209, steps: 222, eps: 0.06399999999999928\n",
      "Finished episode 210, steps: 226, eps: 0.059999999999999276\n",
      "Finished episode 211, steps: 226, eps: 0.05599999999999927\n",
      "Finished episode 212, steps: 229, eps: 0.05199999999999927\n",
      "Finished episode 213, steps: 227, eps: 0.047999999999999265\n",
      "Finished episode 214, steps: 289, eps: 0.04399999999999926\n",
      "Finished episode 215, steps: 219, eps: 0.03999999999999926\n",
      "Finished episode 216, steps: 463, eps: 0.035999999999999255\n",
      "Finished episode 217, steps: 222, eps: 0.03199999999999925\n",
      "Finished episode 218, steps: 213, eps: 0.02799999999999925\n",
      "Finished episode 219, steps: 272, eps: 0.02399999999999925\n",
      "Finished episode 220, steps: 222, eps: 0.01999999999999925\n",
      "Finished episode 221, steps: 290, eps: 0.01599999999999925\n",
      "Finished episode 222, steps: 255, eps: 0.01199999999999925\n",
      "Finished episode 223, steps: 255, eps: 0.01\n",
      "Finished episode 224, steps: 268, eps: 0.01\n",
      "Finished episode 225, steps: 223, eps: 0.01\n",
      "Finished episode 226, steps: 247, eps: 0.01\n",
      "Finished episode 227, steps: 254, eps: 0.01\n",
      "Finished episode 228, steps: 287, eps: 0.01\n",
      "Finished episode 229, steps: 247, eps: 0.01\n",
      "Finished episode 230, steps: 239, eps: 0.01\n",
      "Finished episode 231, steps: 344, eps: 0.01\n",
      "Finished episode 232, steps: 340, eps: 0.01\n",
      "Finished episode 233, steps: 360, eps: 0.01\n",
      "Finished episode 234, steps: 344, eps: 0.01\n",
      "Finished episode 235, steps: 310, eps: 0.01\n",
      "Finished episode 236, steps: 261, eps: 0.01\n",
      "Finished episode 237, steps: 325, eps: 0.01\n",
      "Finished episode 238, steps: 356, eps: 0.01\n",
      "Finished episode 239, steps: 320, eps: 0.01\n",
      "Finished episode 240, steps: 364, eps: 0.01\n",
      "Finished episode 241, steps: 434, eps: 0.01\n",
      "Finished episode 242, steps: 484, eps: 0.01\n",
      "Finished episode 243, steps: 367, eps: 0.01\n",
      "Finished episode 244, steps: 434, eps: 0.01\n",
      "Finished episode 245, steps: 402, eps: 0.01\n",
      "Finished episode 246, steps: 474, eps: 0.01\n",
      "Finished episode 247, steps: 500, eps: 0.01\n",
      "Finished episode 248, steps: 335, eps: 0.01\n",
      "Finished episode 249, steps: 500, eps: 0.01\n",
      "Finished episode 250, steps: 500, eps: 0.01\n",
      "Finished episode 251, steps: 500, eps: 0.01\n",
      "Finished episode 252, steps: 475, eps: 0.01\n",
      "Finished episode 253, steps: 403, eps: 0.01\n",
      "Finished episode 254, steps: 500, eps: 0.01\n",
      "Finished episode 255, steps: 500, eps: 0.01\n",
      "Finished episode 256, steps: 447, eps: 0.01\n",
      "Finished episode 257, steps: 282, eps: 0.01\n",
      "Finished episode 258, steps: 500, eps: 0.01\n",
      "Finished episode 259, steps: 500, eps: 0.01\n",
      "Finished episode 260, steps: 500, eps: 0.01\n",
      "Finished episode 261, steps: 500, eps: 0.01\n",
      "Finished episode 262, steps: 500, eps: 0.01\n",
      "Finished episode 263, steps: 500, eps: 0.01\n",
      "Finished episode 264, steps: 500, eps: 0.01\n",
      "Finished episode 265, steps: 500, eps: 0.01\n",
      "Finished episode 266, steps: 500, eps: 0.01\n",
      "Finished episode 267, steps: 440, eps: 0.01\n",
      "Finished episode 268, steps: 500, eps: 0.01\n",
      "Finished episode 269, steps: 500, eps: 0.01\n",
      "Finished episode 270, steps: 439, eps: 0.01\n",
      "Finished episode 271, steps: 500, eps: 0.01\n",
      "Finished episode 272, steps: 500, eps: 0.01\n",
      "Finished episode 273, steps: 440, eps: 0.01\n",
      "Finished episode 274, steps: 292, eps: 0.01\n",
      "Finished episode 275, steps: 500, eps: 0.01\n",
      "Finished episode 276, steps: 500, eps: 0.01\n",
      "Finished episode 277, steps: 487, eps: 0.01\n",
      "Finished episode 278, steps: 500, eps: 0.01\n",
      "Finished episode 279, steps: 500, eps: 0.01\n",
      "Finished episode 280, steps: 500, eps: 0.01\n",
      "Finished episode 281, steps: 500, eps: 0.01\n",
      "Finished episode 282, steps: 395, eps: 0.01\n",
      "Finished episode 283, steps: 500, eps: 0.01\n",
      "Finished episode 284, steps: 500, eps: 0.01\n",
      "Finished episode 285, steps: 500, eps: 0.01\n",
      "Finished episode 286, steps: 500, eps: 0.01\n",
      "Finished episode 287, steps: 500, eps: 0.01\n",
      "Finished episode 288, steps: 500, eps: 0.01\n",
      "Finished episode 289, steps: 500, eps: 0.01\n",
      "Finished episode 290, steps: 500, eps: 0.01\n",
      "Finished episode 291, steps: 500, eps: 0.01\n",
      "Finished episode 292, steps: 500, eps: 0.01\n",
      "Finished episode 293, steps: 500, eps: 0.01\n",
      "Finished episode 294, steps: 500, eps: 0.01\n",
      "Finished episode 295, steps: 500, eps: 0.01\n",
      "Finished episode 296, steps: 500, eps: 0.01\n",
      "Finished episode 297, steps: 500, eps: 0.01\n",
      "Finished episode 298, steps: 500, eps: 0.01\n",
      "Finished episode 299, steps: 500, eps: 0.01\n",
      "Finished episode 300, steps: 500, eps: 0.01\n",
      "Finished episode 301, steps: 500, eps: 0.01\n",
      "Finished episode 302, steps: 500, eps: 0.01\n",
      "Finished episode 303, steps: 500, eps: 0.01\n",
      "Finished episode 304, steps: 500, eps: 0.01\n",
      "Finished episode 305, steps: 500, eps: 0.01\n",
      "Finished episode 306, steps: 500, eps: 0.01\n",
      "Finished episode 307, steps: 500, eps: 0.01\n",
      "Finished episode 308, steps: 500, eps: 0.01\n",
      "Finished episode 309, steps: 500, eps: 0.01\n",
      "Finished episode 310, steps: 500, eps: 0.01\n",
      "Finished episode 311, steps: 500, eps: 0.01\n",
      "Finished episode 312, steps: 500, eps: 0.01\n",
      "Finished episode 313, steps: 500, eps: 0.01\n",
      "Finished episode 314, steps: 500, eps: 0.01\n",
      "Finished episode 315, steps: 500, eps: 0.01\n",
      "Finished episode 316, steps: 500, eps: 0.01\n",
      "Finished episode 317, steps: 500, eps: 0.01\n",
      "Finished episode 318, steps: 500, eps: 0.01\n",
      "Finished episode 319, steps: 500, eps: 0.01\n",
      "Finished episode 320, steps: 500, eps: 0.01\n",
      "Finished episode 321, steps: 500, eps: 0.01\n",
      "Finished episode 322, steps: 367, eps: 0.01\n",
      "Finished episode 323, steps: 500, eps: 0.01\n",
      "Finished episode 324, steps: 500, eps: 0.01\n",
      "Finished episode 325, steps: 388, eps: 0.01\n",
      "Finished episode 326, steps: 500, eps: 0.01\n",
      "Finished episode 327, steps: 500, eps: 0.01\n",
      "Finished episode 328, steps: 500, eps: 0.01\n",
      "Finished episode 329, steps: 392, eps: 0.01\n",
      "Finished episode 330, steps: 390, eps: 0.01\n",
      "Finished episode 331, steps: 500, eps: 0.01\n",
      "Finished episode 332, steps: 500, eps: 0.01\n",
      "Finished episode 333, steps: 500, eps: 0.01\n",
      "Finished episode 334, steps: 252, eps: 0.01\n",
      "Finished episode 335, steps: 500, eps: 0.01\n",
      "Finished episode 336, steps: 500, eps: 0.01\n",
      "Finished episode 337, steps: 500, eps: 0.01\n",
      "Finished episode 338, steps: 500, eps: 0.01\n",
      "Finished episode 339, steps: 500, eps: 0.01\n",
      "Finished episode 340, steps: 500, eps: 0.01\n",
      "Finished episode 341, steps: 500, eps: 0.01\n",
      "Finished episode 342, steps: 500, eps: 0.01\n",
      "Finished episode 343, steps: 500, eps: 0.01\n",
      "Finished episode 344, steps: 500, eps: 0.01\n",
      "Finished episode 345, steps: 500, eps: 0.01\n",
      "Finished episode 346, steps: 500, eps: 0.01\n",
      "Finished episode 347, steps: 500, eps: 0.01\n",
      "Finished episode 348, steps: 500, eps: 0.01\n",
      "Finished episode 349, steps: 500, eps: 0.01\n",
      "Finished episode 350, steps: 500, eps: 0.01\n",
      "Finished episode 351, steps: 500, eps: 0.01\n",
      "Finished episode 352, steps: 500, eps: 0.01\n",
      "Finished episode 353, steps: 500, eps: 0.01\n",
      "Finished episode 354, steps: 500, eps: 0.01\n",
      "Finished episode 355, steps: 500, eps: 0.01\n",
      "Finished episode 356, steps: 500, eps: 0.01\n",
      "Finished episode 357, steps: 500, eps: 0.01\n",
      "Finished episode 358, steps: 342, eps: 0.01\n",
      "Finished episode 359, steps: 413, eps: 0.01\n",
      "Finished episode 360, steps: 500, eps: 0.01\n",
      "Finished episode 361, steps: 500, eps: 0.01\n",
      "Finished episode 362, steps: 354, eps: 0.01\n",
      "Finished episode 363, steps: 500, eps: 0.01\n",
      "Finished episode 364, steps: 500, eps: 0.01\n",
      "Finished episode 365, steps: 500, eps: 0.01\n",
      "Finished episode 366, steps: 500, eps: 0.01\n",
      "Finished episode 367, steps: 500, eps: 0.01\n",
      "Finished episode 368, steps: 500, eps: 0.01\n",
      "Finished episode 369, steps: 500, eps: 0.01\n",
      "Finished episode 370, steps: 500, eps: 0.01\n",
      "Finished episode 371, steps: 500, eps: 0.01\n",
      "Finished episode 372, steps: 500, eps: 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 28\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# Sample random minibatch from replay mem\u001B[39;00m\n\u001B[32m     27\u001B[39m minibatch = random.sample(replay_mem, \u001B[38;5;28mlen\u001B[39m(replay_mem) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(replay_mem) < minibatch_size \u001B[38;5;28;01melse\u001B[39;00m minibatch_size)\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m y_j = torch.tensor(\u001B[43m[\u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mexp\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexp\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m4\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mexp\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mdiscount\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq_hat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexp\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mminibatch\u001B[49m\u001B[43m]\u001B[49m, dtype=torch.float32)\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m# Calculate loss and perform gradient descent step\u001B[39;00m\n\u001B[32m     31\u001B[39m q_vals = q(torch.stack([torch.tensor(exp[\u001B[32m0\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m exp \u001B[38;5;129;01min\u001B[39;00m minibatch]))\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 28\u001B[39m, in \u001B[36m<listcomp>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# Sample random minibatch from replay mem\u001B[39;00m\n\u001B[32m     27\u001B[39m minibatch = random.sample(replay_mem, \u001B[38;5;28mlen\u001B[39m(replay_mem) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(replay_mem) < minibatch_size \u001B[38;5;28;01melse\u001B[39;00m minibatch_size)\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m y_j = torch.tensor([\u001B[38;5;28mfloat\u001B[39m(exp[\u001B[32m2\u001B[39m]) \u001B[38;5;28;01mif\u001B[39;00m exp[\u001B[32m4\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mfloat\u001B[39m(exp[\u001B[32m2\u001B[39m]) + discount * torch.max(\u001B[43mq_hat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexp\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m).item() \u001B[38;5;28;01mfor\u001B[39;00m exp \u001B[38;5;129;01min\u001B[39;00m minibatch], dtype=torch.float32)\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m# Calculate loss and perform gradient descent step\u001B[39;00m\n\u001B[32m     31\u001B[39m q_vals = q(torch.stack([torch.tensor(exp[\u001B[32m0\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m exp \u001B[38;5;129;01min\u001B[39;00m minibatch]))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 23\u001B[39m, in \u001B[36mMLP.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m   x = F.relu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfc1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     24\u001B[39m   x = F.relu(\u001B[38;5;28mself\u001B[39m.fc2(x))\n\u001B[32m     25\u001B[39m   x = \u001B[38;5;28mself\u001B[39m.fc3(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.linear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m, \u001B[38;5;28mself\u001B[39m.bias)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/rl-learning/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1927\u001B[39m, in \u001B[36mModule.__getattr__\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   1922\u001B[39m         \u001B[38;5;28mself\u001B[39m._backward_pre_hooks = OrderedDict()\n\u001B[32m   1924\u001B[39m \u001B[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001B[39;00m\n\u001B[32m   1925\u001B[39m \u001B[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001B[39;00m\n\u001B[32m   1926\u001B[39m \u001B[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1927\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name: \u001B[38;5;28mstr\u001B[39m) -> Union[Tensor, \u001B[33m\"\u001B[39m\u001B[33mModule\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m   1928\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33m_parameters\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.\u001B[34m__dict__\u001B[39m:\n\u001B[32m   1929\u001B[39m         _parameters = \u001B[38;5;28mself\u001B[39m.\u001B[34m__dict__\u001B[39m[\u001B[33m\"\u001B[39m\u001B[33m_parameters\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(episode_steps, 'o-')\n",
    "plt.title(f'Episode Steps Alive (Episodes 1-{episode + 1})')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Steps Alive')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "d454c72c5e045027"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T03:15:51.854027Z",
     "start_time": "2025-08-05T03:15:39.637687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Demo agent running in test environment\n",
    "\n",
    "input(\"Press Enter to start demo...\")\n",
    "print(\"Demo agent running in test environment\")\n",
    "\n",
    "test_env = gym.make('CartPole-v1', render_mode='human')\n",
    "\n",
    "q.eval()\n",
    "\n",
    "obs, _ = test_env.reset()\n",
    "steps = 0\n",
    "lost = False\n",
    "while not lost:\n",
    "    action = torch.argmax(q(torch.tensor(obs))).item()\n",
    "    obs_next, reward, terminated, truncated, _ = test_env.step(action)\n",
    "    lost = terminated or truncated\n",
    "    obs = obs_next\n",
    "    steps += 1\n",
    "\n",
    "print(\"Steps:\", steps)\n",
    "print(\"Finished demo\")\n",
    "test_env.close()"
   ],
   "id": "58bd4f624b8f65c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo agent running in test environment\n",
      "Steps: 500\n",
      "Finished demo\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reflection\n",
    "\n",
    "I want to use this space to discuss some of the unlocks + conceptual unlocks I got while implementing dqn.\n"
   ],
   "id": "6f4cdddd819c7d7e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
